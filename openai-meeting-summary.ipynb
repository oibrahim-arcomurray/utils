{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdVGprVwT0QcBKncJtVHlC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omargfh/utils/blob/main/openai-meeting-summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "!pip install pydub\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qLxLQwdf5o9",
        "outputId": "f934323c-9821-400d-a70d-7feaac3b54f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRbe01gdf0__"
      },
      "outputs": [],
      "source": [
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error = lambda msg: print(f\"\\033[91m Error:\\t\\t \\033[0m{msg}\")\n",
        "info = lambda msg: print(f\"\\033[94m INFO:\\t\\t \\033[0m{msg}\")\n",
        "success = lambda msg: print(f\"\\033[92m Success:\\t\\t \\033[0m{msg}\")\n",
        "warning = lambda msg: print(f\"\\033[93m Warning:\\t\\t \\033[0m{msg}\")"
      ],
      "metadata": {
        "id": "GtHMLg_Sh7tc"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://blog.devgenius.io/how-to-transcribe-a-video-with-97-accuracy-using-python-f59bbf71d640\n",
        "def transcribe(filepath: str):\n",
        "  try:\n",
        "    # Load the video file\n",
        "    info(\"Converting video file\")\n",
        "    video = AudioSegment.from_file(filepath, format=filepath.split('.')[-1])\n",
        "    audio = video.set_channels(1).set_frame_rate(16000).set_sample_width(2)\n",
        "    audio.export(\"audio.wav\", format=\"wav\")\n",
        "    success(\"Video file converted\")\n",
        "  except Exception as e:\n",
        "    error(e)\n",
        "    raise e\n",
        "\n",
        "  # Initialize recognizer class (for recognizing the speech)\n",
        "  try:\n",
        "    info(\"Initializing Recoginzer\")\n",
        "    r = sr.Recognizer()\n",
        "    success(\"Recognizer Initialized\")\n",
        "  except Exception as e:\n",
        "    error(e)\n",
        "    raise e\n",
        "\n",
        "  # Open the audio file\n",
        "  try:\n",
        "    info(\"Reading audio file\")\n",
        "    with sr.AudioFile(\"audio.wav\") as source:\n",
        "      audio_text = r.record(source)\n",
        "    success(\"Audio File Read\")\n",
        "  except Exception as e:\n",
        "    error(e)\n",
        "    raise e\n",
        "\n",
        "  # Recognize the speech in the audio\n",
        "  try:\n",
        "    info(\"Recognizing Audio\")\n",
        "    text = r.recognize_google(audio_text, language='en-US')\n",
        "    success(\"Audio Recognized\")\n",
        "  except Exception as e:\n",
        "    error(e)\n",
        "    raise e\n",
        "\n",
        "  success(\"Transcription Complete\")\n",
        "\n",
        "  # return transcription\n",
        "  return text"
      ],
      "metadata": {
        "id": "KxYyxkxAf_w4"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(text: str):\n",
        "  def split_text(text):\n",
        "    max_chunk_size = 2048\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    for sentence in text.split(\".\"):\n",
        "        if len(current_chunk) + len(sentence) < max_chunk_size:\n",
        "            current_chunk += sentence + \".\"\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence + \".\"\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "    return chunks\n",
        "\n",
        "  info(\"Generating chunks\")\n",
        "  chunks = split_text(text)\n",
        "  success(\"Chunks generated\")\n",
        "\n",
        "  def _generate_response_sync(prompt):\n",
        "    response = openai.ChatCompletion.create( # Change this\n",
        "        model = \"gpt-3.5-turbo\", # Change this\n",
        "        messages = [ # Change this\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens = 1024,\n",
        "        temperature = 0.5,\n",
        "        stop=None\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "  def generate_summary(input_chunks):\n",
        "    output_chunks = []\n",
        "    for idx, chunk in enumerate(input_chunks):\n",
        "        main_prompt = f\"Please summarize the following meeting transcript and identify the different speakers:\\n{chunk}\\n\\nSummary:\"\n",
        "        alt_prompt = f\"Please summarize this portion of a meeting and identify the different speakers:\\n{chunk}\\n\\nSummary:\"\n",
        "        response = _generate_response_sync(\n",
        "            main_prompt if idx == 0 else alt_prompt\n",
        "        )\n",
        "        summary = response.strip()\n",
        "        output_chunks.append(summary)\n",
        "    return \" \".join(output_chunks)\n",
        "\n",
        "  info(\"Generating summaries\")\n",
        "  return generate_summary(chunks)\n"
      ],
      "metadata": {
        "id": "by29qLVXgUZ_"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_notes(filepath: str, api_key: str):\n",
        "  openai.api_key = api_key\n",
        "  transcript = transcribe(filepath)\n",
        "  with open(\"transcript.txt\", \"w\") as f:\n",
        "    f.write(transcript)\n",
        "  return summarize(transcript)"
      ],
      "metadata": {
        "id": "vQA-0XTzhJ9m"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def execute(filepath: str, api_key: str):\n",
        "  info(\"Starting...\")\n",
        "  notes = generate_notes(\n",
        "      filepath,\n",
        "      api_key\n",
        "  )\n",
        "  success(\"Notes generated\")\n",
        "  with open(\"notes.txt\", \"w\") as f:\n",
        "    info(\"Writing to notes.txt\")\n",
        "    f.write(notes)\n",
        "    success(\"Done...\")"
      ],
      "metadata": {
        "id": "JHVAJosehlJL"
      },
      "execution_count": 73,
      "outputs": []
    }
  ]
}